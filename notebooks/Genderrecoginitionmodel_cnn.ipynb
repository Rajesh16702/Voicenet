{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from voicenet.datasets import stamerican\n",
    "from voicenet.training import GMMModelTraining\n",
    "from voicenet.utils import FeatureExtraction\n",
    "import os\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw\n",
      "Downloading ST American English Corpus...\n",
      "ST-AEDS-20180100_1-OS.tgz already downloaded\n",
      "No extraction was performed !\n",
      "f0001\n",
      "0\n",
      "0\n",
      "{'f0001': [], 'f0002': [], 'f0003': [], 'f0004': [], 'f0005': [], 'm0001': [], 'm0002': [], 'm0003': [], 'm0004': [], 'm0005': []}\n",
      "[]\n",
      "f0002\n",
      "0\n",
      "0\n",
      "{'f0001': [], 'f0002': [], 'f0003': [], 'f0004': [], 'f0005': [], 'm0001': [], 'm0002': [], 'm0003': [], 'm0004': [], 'm0005': []}\n",
      "[]\n",
      "f0003\n",
      "0\n",
      "0\n",
      "{'f0001': [], 'f0002': [], 'f0003': [], 'f0004': [], 'f0005': [], 'm0001': [], 'm0002': [], 'm0003': [], 'm0004': [], 'm0005': []}\n",
      "[]\n",
      "f0004\n",
      "0\n",
      "0\n",
      "{'f0001': [], 'f0002': [], 'f0003': [], 'f0004': [], 'f0005': [], 'm0001': [], 'm0002': [], 'm0003': [], 'm0004': [], 'm0005': []}\n",
      "[]\n",
      "f0005\n",
      "0\n",
      "0\n",
      "{'f0001': [], 'f0002': [], 'f0003': [], 'f0004': [], 'f0005': [], 'm0001': [], 'm0002': [], 'm0003': [], 'm0004': [], 'm0005': []}\n",
      "[]\n",
      "m0001\n",
      "0\n",
      "0\n",
      "{'f0001': [], 'f0002': [], 'f0003': [], 'f0004': [], 'f0005': [], 'm0001': [], 'm0002': [], 'm0003': [], 'm0004': [], 'm0005': []}\n",
      "[]\n",
      "m0002\n",
      "0\n",
      "0\n",
      "{'f0001': [], 'f0002': [], 'f0003': [], 'f0004': [], 'f0005': [], 'm0001': [], 'm0002': [], 'm0003': [], 'm0004': [], 'm0005': []}\n",
      "[]\n",
      "m0003\n",
      "0\n",
      "0\n",
      "{'f0001': [], 'f0002': [], 'f0003': [], 'f0004': [], 'f0005': [], 'm0001': [], 'm0002': [], 'm0003': [], 'm0004': [], 'm0005': []}\n",
      "[]\n",
      "m0004\n",
      "0\n",
      "0\n",
      "{'f0001': [], 'f0002': [], 'f0003': [], 'f0004': [], 'f0005': [], 'm0001': [], 'm0002': [], 'm0003': [], 'm0004': [], 'm0005': []}\n",
      "[]\n",
      "m0005\n",
      "0\n",
      "0\n",
      "{'f0001': [], 'f0002': [], 'f0003': [], 'f0004': [], 'f0005': [], 'm0001': [], 'm0002': [], 'm0003': [], 'm0004': [], 'm0005': []}\n",
      "[]\n",
      "[]\n",
      "Exception raised:  ../data/raw/ST-AEDS/TrainingData could not be created !\n",
      "Exception raised:  ../data/raw/ST-AEDS/TestingData could not be created !\n",
      "Exception raised:  ../data/raw/ST-AEDS/TrainingData/females could not be created !\n",
      "Exception raised:  ../data/raw/ST-AEDS/TrainingData/males could not be created !\n",
      "Exception raised:  ../data/raw/ST-AEDS/TestingData/females could not be created !\n",
      "Exception raised:  ../data/raw/ST-AEDS/TestingData/males could not be created !\n",
      "Moving!\n",
      "[]\n",
      "Moving!\n",
      "[]\n",
      "Moving!\n",
      "[]\n",
      "Moving!\n",
      "[]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# stamerican(direc='./data/raw')\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = stamerican('../data/raw')\n",
    "\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLATTEN FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_features_mfcc(files_list):\n",
    "        \n",
    "        \"\"\" Create features for all '.wav' files contains in files_list\n",
    "        \n",
    "        Arguments:\n",
    "            files_list: takes a list of '.wav' training files\n",
    "\n",
    "        Returns:\n",
    "            features: creates a vector of all .wav training files and stack them over as an array\n",
    "        \"\"\"\n",
    "        \n",
    "        features = np.asarray(())\n",
    "        \n",
    "        for file in files_list:\n",
    "            \n",
    "#             logging.info(\"Creating features for {0}\".format(file))\n",
    "            \n",
    "            # mfccfeatures = mfcc_features()\n",
    "            vector = FeatureExtraction.mfcc_feature(file)\n",
    "            \n",
    "#             print(vector.shape)\n",
    "            \n",
    "            vector1 = np.dot(np.transpose(vector),vector)\n",
    "            \n",
    "#             print(vector1.shape)\n",
    "            \n",
    "            ## If features array is empty then stacking is not possible.\n",
    "            if features.size == 0:\n",
    "                ## Each features will be flatten of 39*39 => 1521\n",
    "                features = vector1.flatten()\n",
    "                \n",
    "            else:\n",
    "                features = np.vstack((features, vector1.flatten()))\n",
    "                \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = flatten_features_mfcc(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2557, 1521)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2557,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "# model.add(layers.Dense(512, activation='relu', )\n",
    "# model.add(layers.Dense(512, activation='relu', input_shape =(X_train.shape[1],)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.50))\n",
    "model.add(layers.Dense(256, activation='relu', input_shape =(X_train.shape[1],)))\n",
    "# model.add(layers.Dense(256, activation='relu'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.50))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "# model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', metrics=['accuracy'], loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.2145 - accuracy: 0.9188 - val_loss: 6.2583e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0467 - accuracy: 0.9966 - val_loss: 9.8333e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0303 - accuracy: 0.9956 - val_loss: 0.0022 - val_accuracy: 0.9980\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 0.9956 - val_loss: 0.0023 - val_accuracy: 0.9980\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0177 - accuracy: 0.9961 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 0.9976 - val_loss: 0.0044 - val_accuracy: 0.9980\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 0.0041 - val_accuracy: 0.9980\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.0051 - val_accuracy: 0.9980\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.0020 - val_accuracy: 0.9980\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 0.0015 - val_accuracy: 0.9980\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.8274e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 8.2766e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9980\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9980\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9961\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.0085 - val_accuracy: 0.9980\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0081 - val_accuracy: 0.9980\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0040 - val_accuracy: 0.9980\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0068 - val_accuracy: 0.9980\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.0044 - val_accuracy: 0.9980\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.0075 - val_accuracy: 0.9980\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0126 - val_accuracy: 0.9980\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0140 - val_accuracy: 0.9980\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 0.0040 - val_accuracy: 0.9980\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 6.5583e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.0027 - val_accuracy: 0.9980\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9980\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0101 - val_accuracy: 0.9980\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 0.0057 - val_accuracy: 0.9980\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9980\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0128 - val_accuracy: 0.9980\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.0039 - val_accuracy: 0.9980\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 0.9971 - val_loss: 0.0139 - val_accuracy: 0.9961\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0103 - val_accuracy: 0.9961\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 0.9985 - val_loss: 0.0109 - val_accuracy: 0.9980\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0073 - val_accuracy: 0.9980\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.9976 - val_loss: 3.5668e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 1.8410e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 7.8723e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.9301e-04 - accuracy: 1.0000 - val_loss: 5.9029e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0025 - val_accuracy: 0.9980\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0029 - val_accuracy: 0.9980\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0073 - val_accuracy: 0.9980\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 2.5495e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.9990 - val_loss: 3.0608e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 3.9214e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0048 - val_accuracy: 0.9980\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0025 - val_accuracy: 0.9980\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0028 - val_accuracy: 0.9980\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 0.9980 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0074 - val_accuracy: 0.9980\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0170 - val_accuracy: 0.9980\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0113 - val_accuracy: 0.9980\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0214 - val_accuracy: 0.9980\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0255 - val_accuracy: 0.9961\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0373 - val_accuracy: 0.9961\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 0.0275 - val_accuracy: 0.9961\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 0.9985 - val_loss: 0.0197 - val_accuracy: 0.9961\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0081 - val_accuracy: 0.9980\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0081 - val_accuracy: 0.9980\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0059 - val_accuracy: 0.9980\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0103 - val_accuracy: 0.9961\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 0.0097 - val_accuracy: 0.9961\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0340 - val_accuracy: 0.9980\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0398 - val_accuracy: 0.9980\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0836 - val_accuracy: 0.9941\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.6308e-04 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9941\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.6471e-04 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9941\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0776 - val_accuracy: 0.9941\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.1019 - val_accuracy: 0.9922\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.1172 - val_accuracy: 0.9941\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.4920e-04 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9922\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.7044e-04 - accuracy: 0.9995 - val_loss: 0.0992 - val_accuracy: 0.9941\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8114e-04 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9941\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.1300 - val_accuracy: 0.9941\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.9385e-04 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9941\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.8333e-04 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9941\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.9990 - val_loss: 0.1452 - val_accuracy: 0.9941\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0769e-04 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9922\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3776e-04 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9922\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.8467e-04 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9922\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0737e-04 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9922\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.1506 - val_accuracy: 0.9922\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.5253e-04 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9922\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1328 - val_accuracy: 0.9941\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1650 - val_accuracy: 0.9941\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9022e-04 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9941\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.1589 - val_accuracy: 0.9941\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.0440e-04 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9941\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.8437e-04 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9941\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7050e-04 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9941\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5093e-04 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9941\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.1000 - val_accuracy: 0.9941\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.0342 - val_accuracy: 0.9980\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.9976 - val_loss: 0.0769 - val_accuracy: 0.9980\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0722 - val_accuracy: 0.9980\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 0.9985 - val_loss: 0.0595 - val_accuracy: 0.9980\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.7248e-04 - accuracy: 0.9995 - val_loss: 0.0875 - val_accuracy: 0.9980\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.1160 - val_accuracy: 0.9961\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.1310 - val_accuracy: 0.9980\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.6694e-04 - accuracy: 0.9995 - val_loss: 0.0921 - val_accuracy: 0.9980\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.1064 - val_accuracy: 0.9980\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 0.1400 - val_accuracy: 0.9980\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6619e-04 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9961\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3055e-04 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9961\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1376 - val_accuracy: 0.9961\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1348 - val_accuracy: 0.9961\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.0790 - val_accuracy: 0.9980\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.0719 - val_accuracy: 0.9980\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.0215 - val_accuracy: 0.9961\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0678 - val_accuracy: 0.9980\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 5.2992e-04 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9980\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.0049e-04 - accuracy: 0.9995 - val_loss: 0.0535 - val_accuracy: 0.9961\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0636 - val_accuracy: 0.9980\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0407 - val_accuracy: 0.9961\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.8698e-04 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9961\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.6973e-04 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.9961\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.5386e-04 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9961\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6028e-04 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9961\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.8870e-04 - accuracy: 0.9995 - val_loss: 0.0192 - val_accuracy: 0.9961\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.9990 - val_loss: 0.0399 - val_accuracy: 0.9961\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.5327e-04 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 0.9961\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7670e-04 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9980\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0183 - val_accuracy: 0.9980\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4946e-04 - accuracy: 1.0000 - val_loss: 3.6933e-04 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5872e-04 - accuracy: 1.0000 - val_loss: 5.6020e-04 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0138 - val_accuracy: 0.9980\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.4490e-04 - accuracy: 0.9995 - val_loss: 0.0284 - val_accuracy: 0.9980\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9937e-04 - accuracy: 0.9995 - val_loss: 0.0554 - val_accuracy: 0.9980\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.7916e-05 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9961\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.5974e-04 - accuracy: 0.9995 - val_loss: 0.0575 - val_accuracy: 0.9961\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.1370e-04 - accuracy: 0.9995 - val_loss: 0.0766 - val_accuracy: 0.9961\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0991 - val_accuracy: 0.9961\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5165e-04 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9961\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 0.9985 - val_loss: 0.1844 - val_accuracy: 0.9961\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.0937e-04 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9961\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.7290e-04 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9961\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0052e-04 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9961\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.4281e-05 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9961\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9187e-04 - accuracy: 0.9995 - val_loss: 0.2334 - val_accuracy: 0.9941\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.2286 - val_accuracy: 0.9941\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.2322 - val_accuracy: 0.9961\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2125 - val_accuracy: 0.9961\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0021e-04 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9961\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.5911e-04 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9961\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2115e-04 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9961\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0006e-04 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9961\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9219e-05 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9961\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9287e-05 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9961\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7461e-04 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9961\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.7199e-05 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9961\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.7327e-05 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9961\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.9112e-05 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9961\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9691e-05 - accuracy: 1.0000 - val_loss: 0.1521 - val_accuracy: 0.9961\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.2393e-05 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9961\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.1641e-05 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9961\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0902e-04 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9961\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.1225e-05 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9961\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.2840e-05 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9961\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.7966e-04 - accuracy: 0.9995 - val_loss: 0.1885 - val_accuracy: 0.9961\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.1669 - val_accuracy: 0.9961\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.5761e-05 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9961\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.0143e-04 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9961\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.3697e-04 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9961\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.1238e-04 - accuracy: 0.9995 - val_loss: 0.2131 - val_accuracy: 0.9961\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.5579e-05 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9961\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.9999e-05 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9961\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 1.8259e-04 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9961\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.6525e-05 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9961\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.0607e-05 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9961\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.7400e-05 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9961\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.2689e-05 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9961\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.0661e-05 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9961\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9755e-05 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9961\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1570e-04 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9961\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.0920e-04 - accuracy: 0.9995 - val_loss: 0.2117 - val_accuracy: 0.9961\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.6270e-04 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9961\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0095e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9961\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9984e-05 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9961\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9574e-04 - accuracy: 0.9995 - val_loss: 0.2688 - val_accuracy: 0.9961\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.2788e-04 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9961\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.6641e-05 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9961\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.5707e-05 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9961\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.2267e-05 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9961\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5822e-05 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9961\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1564e-04 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9961\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2576e-05 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9961\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.1320e-05 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9961\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.7614e-05 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9961\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5754e-05 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9961\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.0822e-04 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9961\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3339e-04 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9961\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0430 - val_accuracy: 0.9961\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.1490 - val_accuracy: 0.9961\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.3040e-04 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9961\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.8183e-05 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9961\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.1603 - val_accuracy: 0.9961\n"
     ]
    }
   ],
   "source": [
    "history  = model.fit(X_train,np.array(np.array(y_train).reshape((len(y_train),1))), epochs=200, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = models.Sequential()\n",
    "\n",
    "cnn_model.add(layers.Conv1D(128, (3), activation='relu', input_shape=(X_train.shape[1],1)))\n",
    "cnn_model.add(Dropout(0.15))\n",
    "cnn_model.add(layers.MaxPool1D(2))\n",
    "cnn_model.add(layers.Conv1D(64, (3), activation='relu'))\n",
    "cnn_model.add(Dropout(0.15))\n",
    "cnn_model.add(layers.MaxPool1D(2))\n",
    "cnn_model.add(layers.Flatten())\n",
    "cnn_model.add(layers.Dense(32, activation='relu'))\n",
    "cnn_model.add(Dropout(0.15))\n",
    "cnn_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/ridhima/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /home/ridhima/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ridhima/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ridhima/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ridhima/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /home/ridhima/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /home/ridhima/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer sequential_10 is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 39, 39]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-836855756ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2772\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 2774\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2704\u001b[0m         relaxed_arg_shapes)\n\u001b[1;32m   2705\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 2706\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   2707\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/ridhima/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /home/ridhima/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ridhima/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ridhima/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ridhima/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /home/ridhima/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /home/ridhima/Documents/Github/Voicenet/voicenet_venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer sequential_10 is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 39, 39]\n"
     ]
    }
   ],
   "source": [
    "history  = cnn_model.fit(X_train,np.array(np.array(y_train).reshape((len(y_train),1))), epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_features(files_list):\n",
    "        \n",
    "        \"\"\" Create features for all '.wav' files contains in files_list\n",
    "        \n",
    "        Arguments:\n",
    "            files_list: takes a list of '.wav' training files\n",
    "\n",
    "        Returns:\n",
    "            features: creates a vector of all .wav training files and stack them over as an array\n",
    "        \"\"\"\n",
    "        \n",
    "        features = list()\n",
    "        \n",
    "        for file in files_list:\n",
    "            \n",
    "#             logging.info(\"Creating features for {0}\".format(file))\n",
    "            \n",
    "            # mfccfeatures = mfcc_features()\n",
    "            vector = FeatureExtraction.mfcc_feature(file)\n",
    "            vector = stats.zscore(vector, axis=1, ddof=1)\n",
    "            \n",
    "#             print(vector.shape)\n",
    "            \n",
    "            vector1 = np.dot(np.transpose(vector),vector)\n",
    "        \n",
    "            features.append(np.array(vector1))\n",
    "            \n",
    "#             print(vector1.shape)\n",
    "            \n",
    "            ## If features array is empty then stacking is not possible.\n",
    "#             if features.size == 0:\n",
    "#                 features = vector1.flatten()\n",
    "                \n",
    "#             else:\n",
    "#                 features = np.vstack((features, vector1.flatten()))\n",
    "                \n",
    "        return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = collect_features(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[ 2.06327489e+03  7.56978825e+02 -7.29271928e+01 ...  4.56762291e+00\n",
      "   3.77279795e+00  3.66732413e+00]\n",
      " [ 7.56978825e+02  1.35733581e+03 -3.60017058e+02 ...  3.79838401e+01\n",
      "   4.43780573e+01  4.42390951e+01]\n",
      " [-7.29271928e+01 -3.60017058e+02  1.00101318e+03 ... -1.06678050e+01\n",
      "  -6.76223287e+00  1.21822293e+00]\n",
      " ...\n",
      " [ 4.56762291e+00  3.79838401e+01 -1.06678050e+01 ...  3.58755747e+01\n",
      "   1.30190108e+01  1.55445531e+01]\n",
      " [ 3.77279795e+00  4.43780573e+01 -6.76223287e+00 ...  1.30190108e+01\n",
      "   2.44189340e+01  1.39717844e+01]\n",
      " [ 3.66732413e+00  4.42390951e+01  1.21822293e+00 ...  1.55445531e+01\n",
      "   1.39717844e+01  3.45241712e+01]]\n"
     ]
    }
   ],
   "source": [
    "# X_train = np.array(X_train)[indices.astype(int)]\n",
    "print(type(X_train))\n",
    "print(X_train[0])\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = models.Sequential()\n",
    "\n",
    "cnn_model.add(layers.Conv2D(128, (3,3), activation='relu', input_shape=(X_train.shape[1],X_train.shape[2],1)))\n",
    "cnn_model.add(Dropout(0.15))\n",
    "cnn_model.add(layers.MaxPool2D(2,2))\n",
    "cnn_model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "cnn_model.add(Dropout(0.15))\n",
    "cnn_model.add(layers.MaxPool2D(2,2))\n",
    "cnn_model.add(layers.Flatten())\n",
    "cnn_model.add(layers.Dense(32, activation='relu'))\n",
    "cnn_model.add(Dropout(0.15))\n",
    "cnn_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam', metrics=['accuracy'], loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "64/64 [==============================] - 5s 83ms/step - loss: 2.9412 - accuracy: 0.8386 - val_loss: 0.0866 - val_accuracy: 0.9668\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 5s 82ms/step - loss: 0.1027 - accuracy: 0.9663 - val_loss: 0.0516 - val_accuracy: 0.9863\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 5s 83ms/step - loss: 0.0797 - accuracy: 0.9711 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 6s 86ms/step - loss: 0.0681 - accuracy: 0.9760 - val_loss: 0.0640 - val_accuracy: 0.9766\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.0559 - accuracy: 0.9809 - val_loss: 0.0092 - val_accuracy: 0.9980\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.0437 - accuracy: 0.9883 - val_loss: 0.0654 - val_accuracy: 0.9785\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 6s 86ms/step - loss: 0.0406 - accuracy: 0.9824 - val_loss: 0.0196 - val_accuracy: 0.9980\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 0.0405 - accuracy: 0.9897 - val_loss: 0.0134 - val_accuracy: 0.9980\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 6s 87ms/step - loss: 0.0411 - accuracy: 0.9848 - val_loss: 0.0343 - val_accuracy: 0.9922\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 0.0549 - accuracy: 0.9804 - val_loss: 0.0074 - val_accuracy: 0.9980\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 6s 87ms/step - loss: 0.0310 - accuracy: 0.9922 - val_loss: 0.0046 - val_accuracy: 0.9980\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0192 - accuracy: 0.9951 - val_loss: 0.0026 - val_accuracy: 0.9980\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 6s 91ms/step - loss: 0.0251 - accuracy: 0.9941 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 0.0068 - val_accuracy: 0.9980\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0165 - accuracy: 0.9927 - val_loss: 0.0029 - val_accuracy: 0.9980\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0103 - val_accuracy: 0.9941\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 0.0117 - accuracy: 0.9985 - val_loss: 0.0057 - val_accuracy: 0.9980\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 6s 91ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.1647 - val_accuracy: 0.9629\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 6s 92ms/step - loss: 0.0394 - accuracy: 0.9863 - val_loss: 0.0140 - val_accuracy: 0.9980\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 6s 87ms/step - loss: 0.0263 - accuracy: 0.9912 - val_loss: 0.0205 - val_accuracy: 0.9902\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 6s 87ms/step - loss: 0.0375 - accuracy: 0.9883 - val_loss: 0.0021 - val_accuracy: 0.9980\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.0088 - val_accuracy: 0.9980\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0147 - val_accuracy: 0.9980\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0065 - val_accuracy: 0.9980\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 0.0318 - val_accuracy: 0.9980\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 6s 87ms/step - loss: 0.0181 - accuracy: 0.9917 - val_loss: 0.0073 - val_accuracy: 0.9980\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.0070 - val_accuracy: 0.9980\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0434 - accuracy: 0.9907 - val_loss: 0.0063 - val_accuracy: 0.9980\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 0.0211 - accuracy: 0.9927 - val_loss: 0.0071 - val_accuracy: 0.9980\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0104 - val_accuracy: 0.9980\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.0103 - val_accuracy: 0.9980\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.0029 - val_accuracy: 0.9980\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.0049 - val_accuracy: 0.9980\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 6s 92ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 5.4026e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0026 - val_accuracy: 0.9980\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 6s 91ms/step - loss: 0.0166 - accuracy: 0.9956 - val_loss: 0.0103 - val_accuracy: 0.9961\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0051 - val_accuracy: 0.9980\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 6s 94ms/step - loss: 0.0131 - accuracy: 0.9990 - val_loss: 0.0064 - val_accuracy: 0.9980\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 6s 92ms/step - loss: 0.0145 - accuracy: 0.9946 - val_loss: 0.0526 - val_accuracy: 0.9883\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 0.0288 - accuracy: 0.9902 - val_loss: 0.0033 - val_accuracy: 0.9980\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 9.0616e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 0.0380 - accuracy: 0.9888 - val_loss: 0.0172 - val_accuracy: 0.9961\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0073 - val_accuracy: 0.9980\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 6.3880e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 6s 92ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0049 - val_accuracy: 0.9980\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0035 - accuracy: 0.9980 - val_loss: 0.0017 - val_accuracy: 0.9980\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0279 - accuracy: 0.9936 - val_loss: 0.0948 - val_accuracy: 0.9844\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.0043 - val_accuracy: 0.9980\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 6s 91ms/step - loss: 0.0053 - accuracy: 0.9971 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 6s 91ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0046 - val_accuracy: 0.9980\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.0204 - val_accuracy: 0.9922\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 0.0050 - accuracy: 0.9980 - val_loss: 0.0059 - val_accuracy: 0.9980\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 6s 87ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.0225 - val_accuracy: 0.9922\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 5.6437e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 6s 87ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0042 - accuracy: 0.9976 - val_loss: 0.0038 - val_accuracy: 0.9980\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 5s 85ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0090 - val_accuracy: 0.9980\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 6s 87ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.0026 - val_accuracy: 0.9980\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 6s 87ms/step - loss: 0.0079 - accuracy: 0.9966 - val_loss: 0.0166 - val_accuracy: 0.9961\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0268 - val_accuracy: 0.9922\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 0.0159 - accuracy: 0.9971 - val_loss: 1.4501e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.0098 - val_accuracy: 0.9941\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 6s 87ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 4.7036e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 5s 82ms/step - loss: 0.0179 - accuracy: 0.9932 - val_loss: 0.0210 - val_accuracy: 0.9941\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 5s 82ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0163 - val_accuracy: 0.9980\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 0.0360 - val_accuracy: 0.9883\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.0032 - accuracy: 0.9985 - val_loss: 0.0052 - val_accuracy: 0.9980\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 5s 82ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9941\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 5s 84ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 9.2733e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 5s 82ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 5.6904e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 5s 82ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0312 - val_accuracy: 0.9902\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 1.9084e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 1.6119e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.0201 - accuracy: 0.9951 - val_loss: 0.0069 - val_accuracy: 0.9980\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.0053 - val_accuracy: 0.9980\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.0057 - accuracy: 0.9971 - val_loss: 0.0118 - val_accuracy: 0.9941\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0133 - val_accuracy: 0.9980\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 6s 90ms/step - loss: 0.0769 - accuracy: 0.9844 - val_loss: 0.0657 - val_accuracy: 0.9844\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.0188 - accuracy: 0.9946 - val_loss: 3.1442e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 5s 83ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 6.2123e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.0084 - accuracy: 0.9966 - val_loss: 2.8580e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 1.2420e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 4.4730e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 5s 82ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 3.1869e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 5s 85ms/step - loss: 0.0027 - accuracy: 0.9985 - val_loss: 0.0051 - val_accuracy: 0.9980\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 5s 85ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 6.3221e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 5s 85ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 2.5202e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 5s 85ms/step - loss: 8.2228e-04 - accuracy: 1.0000 - val_loss: 1.1282e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 5s 85ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 4.1572e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 5s 85ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 4.5146e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 1.0073e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history  = cnn_model.fit(X_train,np.array(np.array(y_train).reshape((len(y_train),1))), epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1]\n",
      "(3,)\n",
      "[[2]\n",
      " [1]\n",
      " [1]]\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([2,1,1])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "x = x.reshape(3,1)\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2557, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.array(y_train).reshape((len(y_train),1))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.9765625"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2557/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.array(y_train).reshape((len(y_train),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('voicenet_venv': venv)",
   "language": "python",
   "name": "python37564bitvoicenetvenvvenv3211909c721248e184b0b91a67b5318b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
